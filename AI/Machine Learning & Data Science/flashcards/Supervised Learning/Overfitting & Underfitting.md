#flashcards

What is overfitting in machine learning?
?
Overfitting occurs when a model learns the training data too well, capturing noise and outliers, leading to poor generalization on unseen data.

List three causes of overfitting.
?
1. Complex Model 2. Noisy Data 3. Insufficient Data

What are acceptable remedies for overfitting?
?
1. Simplifying the model 2. Acquiring more data 3. Applying regularisation techniques

What is one technique to evaluate models better and prevent overfitting?
?
Using k-fold cross-validation for evaluation.

What is underfitting in machine learning?
?
Underfitting occurs when a model is too simple to capture the underlying structure of the data, resulting in inaccurate predictions.

List three causes of underfitting.
?
1. Simple Model 2. Insufficient Features 3. Over-Regularisation

What is a common remedy for underfitting?
?
Using a more complex model or adding more features.

What is the bias-variance tradeoff?
?
The bias-variance tradeoff refers to the balance between the error due to bias (underfitting) and the error due to variance (overfitting) in machine learning models.

Why is regularisation important?
?
Regularisation helps prevent overfitting by adding a penalty on the complexity of the model.

What is early stopping?
?
Early stopping is a technique where the training process is halted when validation performance begins to degrade.

What is the purpose of learning curve analysis?
?
Learning curve analysis helps understand how a model's performance changes with more data or training time, indicating whether it suffers from underfitting or overfitting.

How does ensemble methods help with model performance?
?
Ensemble methods combine multiple models to reduce noise and improve generalization.

What role does hyperparameter tuning play in machine learning?
?
Hyperparameter tuning optimizes the parameters of the model to improve its performance on training and validation data.

What should you always ensure regarding data split?
?
Always maintain separate training, validation, and test sets.

What is one potential consequence of using an overly complex model?
?
It can lead to overfitting, whereby the model performs well on the training data but poorly on unseen data.

What techniques can be used for hyperparameter tuning?
?
Grid Search or Random Search with Cross-Validation.

