**Okapi BM25** (BM stands for Best Matching) is a ranking function used by search engines to estimate the relevance of documents to a given search query. It is a [[AI/Machine Learning & Data Science/Natural Language Processing/Bag of Words|bag-of-words]] retrieval function that ranks a set of documents based on the query terms appearing in each document, regardless of their proximity within the document.

BM25 is an evolution of the [[AI/Machine Learning & Data Science/Natural Language Processing/Term Frequency-Inverse Document Frequency|TF-IDF (Term Frequency-Inverse Document Frequency)]] model and is considered a cornerstone in information retrieval, bridging traditional search algorithms and modern generative AI.
## Core Concepts
The BM25 algorithm provides a nuanced approach to ranking by considering three main factors:
1.  **Term Frequency (TF):** How often a query term appears in a document. BM25 uses a saturation function, meaning that after a certain point, more occurrences of a term don't proportionally increase the score. This prevents very long documents from dominating just by having more instances of a word.
2.  **Inverse Document Frequency (IDF):** Measures how common or rare a term is across all documents. Common terms (like "the" or "a") are penalised and have a lower IDF score, while rare terms are considered more significant and receive a higher score.
3.  **Document Length:** The length of the document. BM25 normalises for document length, so shorter documents that contain the query term are ranked higher than longer documents, assuming all other factors are equal.
## The BM25 Formula
The score of a document *D* for a query *Q* containing terms *q₁, q₂, ..., qₙ* is calculated as:
$$
\text{score}(D, Q) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})}
$$
Where:
-   $f(q_i, D)$ is the term frequency of term $q_i$ in document $D$.
-   $|D|$ is the length of the document $D$.
-   $avgdl$ is the average document length in the collection.
-   $k_1$ and $b$ are free parameters, usually set to $k₁ ∈ [1.2, 2.0]$ and $b = 0.75$.
    -   $k_1$ controls the term frequency saturation.
    -   $b$ controls the document length normalisation.
-   $IDF(q_i)$ is the inverse document frequency of the term $q_i$.
## Relationship with Other Models
-   **TF-IDF:** BM25 is an improvement over TF-IDF. While both use TF and IDF components, BM25 adds document length normalisation and term frequency saturation, which generally leads to better relevance ranking.
-   **Vector Search & LLMs:** BM25 is a term-based (lexical) search method, whereas vector search is semantic. They can be combined in a hybrid approach. BM25 can efficiently retrieve a set of potentially relevant documents based on keywords, which can then be re-ranked by a more computationally expensive model like a Large Language Model (LLM) or a vector-based model to improve semantic understanding and final ranking. This combination helps improve accuracy and reduce hallucinations in generative AI applications.
## History and Modern Usage
BM25 was developed in the 1970s as part of the Okapi Information Retrieval System project, which is why it is often referred to as "Okapi BM25". It was built on the probabilistic relevance framework and quickly became a standard and highly influential ranking function in the field of information retrieval.

For many years, it was a core component of the search algorithms used by major search engines and is still the default scoring algorithm in popular open-source search libraries like **Apache Lucene** (which powers **Elasticsearch** and **Solr**).

Despite being decades old, BM25 is still widely used today. Its popularity persists due to its speed, simplicity, and robust performance for keyword-based (lexical) search. It is often used as a strong baseline or as the first stage in a more complex, multi-stage ranking architecture (e.g., in a hybrid search system that combines it with other vector search methods for semantic understanding).


